{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e177425c-602c-42c3-8d92-7f01ab277d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdef8b38-315f-4668-9602-93eb25bb3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Files/full_merge_advance_max_with_ethnicity_and_gender.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5901f66-c4a1-48d3-a449-b4434a9da752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def fix_spelling_mistake_for_rows_in_full_merge_data(dx):\n",
    "    dx.loc[11395,'All'] = \"NYT bestselling author Mark Bego's complete and up-to-the-moment WHITNEY HOUSTON: THE BIOGRAPHY, again to Jay Cassell at Skyhorse, in a nice deal, for nearly-instant publication just in advance of Skyhorse's scheduled April publication of Bego's biography of Houston's godmother, Aretha Franklin, by Scott Mendel at the Mendel Media Group (NA).\\nTranslation: scott@mendelmedia.com\"\n",
    "    dx.loc[2543:2544,'All'] = \"Donna Alward's next three romances, again to Sally Williamson at Harlequin Romance, in a nice deal, by Jennifer Schober at Spencerhill Associates (world).\\njschober@spencerhillassociates.com\"\n",
    "    dx.loc[13077:13085,'All'] = \"Author of the Vespasian series Robert Fabbri's TO THE STRONGEST, a story of treacherous generals, scheming princesses, epic battles and exotic warrior queens, set in a historical era that echoes GAME OF THRONESÃ¢â‚¬â€\\x9dthe period that followed the death of Alexander the Great, with intrigues, murders, and an eventual civil war to Sarah O'Keefe at Corvus, in a good deal, in a three-book deal, for publication in summer 2020, by Ian Drury at Sheil Land Associates (world English).\"\n",
    "    dx.loc[13622,'All'] = \"Heidi Mastrogiovanni's LALA PETTIBONE'S ACT TWO, pitched as a humorous account of a modern-day Bridget Jones finding inspiration again after her life falls apart, to Kayla Church at Amberjack, in a nice deal, for publication in February 2017.\"\n",
    "    dx.loc[14066,'All'] = \"Matthew Wilson's THE BLACKBIRD SINGULARITY, a first-person literary novel about the struggle to start a new life after losing a child, to Lauren Parson at Legend Press, in a nice deal, by David Haviland at the Andrew Lownie Literary Agency (World English).\"\n",
    "    dx.loc[88:94,'All'] = \"Bestselling author of historical fiction and novels featuring eponymous hero Richard Sharpe, Bernard Cornwell's next four untitled novels, announced shortly before publication of his 50th book, 1356, to Jonathan Burnham and Jennifer Barth at Harper, and Kate Elton and Katie Espiner at Harper Fiction, in a major deal, for publication through 2017, by Toby Eady at Toby Eady Associates (world English).\"\n",
    "    \n",
    "    \n",
    "def extract_from_pattern_to_name_and_name_at(dx):\n",
    "    \n",
    "    pattern = r\"to ([\\w\\s]+) and ([\\w\\s]+) at\"\n",
    "    dx.loc[dx['Editor'].apply(len) > 1, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.contains(pattern),\n",
    "                                                        dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.extract(pattern).apply(lambda x: x.tolist(), axis=1),\n",
    "                                                        np.nan)\n",
    "    \n",
    "def extract_from_pattern_to_name_at(dx):\n",
    "    pattern = r\"to ([\\w\\s]+) at\"\n",
    "    \n",
    "    dx.loc[dx['Editor'].isna(), 'Editor'] = np.where(dx.loc[dx['Editor'].isna(), 'All'].str.contains(pattern),\n",
    "                                                        dx.loc[dx['Editor'].isna(), 'All'].str.extract(pattern).apply(lambda x: x.tolist(), axis=1),\n",
    "                                                        np.nan)\n",
    "def extract_from_pattern_to_name_at_array(dx):\n",
    "    pattern = r\"to ([\\w\\s]+) at\"\n",
    "    \n",
    "    dx.loc[dx['Editor'].apply(len)==0, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len)==0, 'All'].str.contains(pattern),\n",
    "                                                        dx.loc[dx['Editor'].apply(len)==0, 'All'].str.extract(pattern).apply(lambda x: x.tolist(), axis=1),\n",
    "                                                        np.nan)\n",
    "def get_editor_ent_nlp_to_at(text):\n",
    "    doc = nlp(text)\n",
    "    names = []\n",
    "    for d in doc.ents:\n",
    "        '''\n",
    "        if d.text in ['Vikki Ciaffone', 'Cassie Jones]':\n",
    "            d.label_ = 'PERSON'\n",
    "        '''\n",
    "        if f\"to {d.text} at\" in doc.text and (d.label_ == 'PERSON' or d.label_ == 'ORG') :\n",
    "            names.append(d.text)\n",
    "            break\n",
    "    return names\n",
    "\n",
    "def get_editor_ent_nlp_to(text):\n",
    "    doc = nlp(text)\n",
    "    names = []\n",
    "    for d in doc.ents:\n",
    "        '''\n",
    "        if d.text in ['Vikki Ciaffone', 'Cassie Jones]':\n",
    "            d.label_ = 'PERSON'\n",
    "           '''\n",
    "        if f\"to {d.text}\" in doc.text and \"'s\" not in d.text and f\"{d.text}'s\" not in doc.text and (d.label_ == 'PERSON' or d.label_ == 'ORG'):#or d.label_ == 'ORG'\n",
    "            names.append(d.text)\n",
    "    return names\n",
    "\n",
    "def get_editor(df, column):\n",
    "    \n",
    "    fix_spelling_mistake_for_rows_in_full_merge_data(df)\n",
    "    df['Editor'] = df[column].apply(lambda text : get_editor_ent_nlp_to_at(text))\n",
    "    #df['Editor'] = df['Editor'].astype('str')\n",
    "    #df['Editor'] = df['Editor'].str.slice(start=2, stop = -2)\n",
    "    \n",
    "    #temp_df = df[df['Editor'] =='']\n",
    "    #temp_df['Editor'] = temp_df[column].apply(lambda text : get_editor_ent_nlp_to(text))\n",
    "    #temp_df['Editor'] = temp_df['Editor'].astype('str')\n",
    "    #temp_df['Editor'] = temp_df['Editor'].str.slice(start=2, stop = -2)\n",
    "    df.loc[df['Editor'].apply(len) == 0 , 'Editor']  = df.loc[df['Editor'].apply(len)==0, 'All'].apply(lambda text : get_editor_ent_nlp_to(text))\n",
    "    #df.loc[df['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'] = df.loc[df['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'].apply(lambda x: ', '.join(map(str, x)))\n",
    "    #df.loc[df['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'] = df.loc[df['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'].apply(lambda x: x[1:-1])\n",
    "    extract_from_pattern_to_name_and_name_at(df)\n",
    "    #fix_spelling_mistake_for_rows_in_full_merge_data(df)\n",
    "    extract_from_pattern_to_name_at(df)\n",
    "\n",
    "    df.loc[df['Editor'].isna() , 'Editor']  = df.loc[df['Editor'].isna(), 'All'].apply(lambda text : get_editor_ent_nlp_to(text))\n",
    "    extract_from_pattern_to_name_at_array(df)\n",
    "    #df = pd.merge(df, temp_df, on=['isbn13'])\n",
    "    \n",
    "    #clean if editor names has at for of\n",
    "    pattern = r'\\b(for|of|at)\\b.*'\n",
    "    df.loc[~df['Editor'].isna(),'Editor'] = df.loc[~df['Editor'].isna(),'Editor'].str.replace(pattern, '', regex=True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_advance_seven_figures_from_text(df,column):\n",
    "    df.loc[df['All'].str.contains('seven figures', case=False, na=False), 'Advance'] = 10**7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ad23d3-41f2-4485-8917-7516a4bc0c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-02eb6277ffdf>:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx.loc[dx['Editor'].apply(len) > 1, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.contains(pattern),\n",
      "<ipython-input-8-02eb6277ffdf>:23: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx.loc[dx['Editor'].isna(), 'Editor'] = np.where(dx.loc[dx['Editor'].isna(), 'All'].str.contains(pattern),\n",
      "<ipython-input-8-02eb6277ffdf>:29: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx.loc[dx['Editor'].apply(len)==0, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len)==0, 'All'].str.contains(pattern),\n"
     ]
    }
   ],
   "source": [
    "dx = get_editor(df, 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c637c3-3e66-499b-9add-7f8b3ed01a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_advance_seven_figures_from_text(dx, 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14fc7cf-528c-4ca3-83f8-2d28caf1a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.to_csv('Editor_merge_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acd568b8-72fc-41ce-9217-a1678a39947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = pd.read_csv('Editor_merge_new.csv')\n",
    "\n",
    "# Remove everything after 'for', 'at', 'of' including the words\n",
    "pattern = r'\\b(for|of|at)\\b.*'\n",
    "\n",
    "# Apply the removal of text after the keywords only if they are present\n",
    "dx.loc[~dx['Editor'].isna(),'Editor'] = dx.loc[~dx['Editor'].isna(),'Editor'].str.replace(pattern, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de10a289-f18f-4aa3-b8bd-de389d41a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.to_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d542cc0-930d-43cd-a48e-7f0d72d682ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['Meredith Mundy at']\n",
    "dx['Editor'] = dx['Editor'].fillna(pd.Series([[]] * len(dx)))\n",
    "#dx['Editor'] = dx['Editor'].apply(lambda x: x if isinstance(x, list) else [x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fef91dac-f5ac-49f2-a19a-3221cdc7f13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1a33400e691c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split the names into different columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Editor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_elements\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3947\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3948\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3949\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3950\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3989\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3990\u001b[0;31m                 \u001b[0mcheck_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3991\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3992\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mcheck_key_length\u001b[0;34m(columns, key, value)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# Missing keys in columns are represented as -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "max_elements = dx['Editor'].apply(len).max()\n",
    "\n",
    "# Create new column names for each element index\n",
    "column_names = [f'Editor{i+1}' for i in range(max_elements)]\n",
    "\n",
    "# Split the names into different columns\n",
    "dx[column_names] = dx['Editor'].apply(lambda x: pd.Series(x[:max_elements]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88926b-d194-4c7e-ab68-6191a37342a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b81d3a-bd28-495c-bb92-dcd7560e8914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62599f23-b834-4a10-a96f-5ea6ef4a3d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb381a5a-6f4a-4d41-b8ed-a207288b2475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Author of MY SISTER'S SECRET Tracy Buchanan's THE WEIGHT OF SILENCE, in which a physiotherapist comes home from work to find her husband unconscious on the floor with a stab wound and their three children standing around him; it's clear he has been stabbed by one of them, but none of them is willing to say who did it or why, and THE WOMAN IN THE WOODS, to Sammia Hamer at Lake Union Publishing, in a very nice deal, by Caroline Hardman at Hardman & Swainson (world English).\\ncaroline@hardmanswainson.com\\nRights: Therese Coen at Hardman & Swainson\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[dx['Editor'].apply(len)==0]['All'][167] #14067 #14042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9a800100-7329-42cc-b338-e54f66b21253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bestselling author of historical fiction and novels featuring eponymous hero Richard Sharpe, Bernard Cornwell's next four untitled novels, announced shortly before publication of his 50th book, 1356, to Jonathan Burnham andJennifer Barth at Harper, and Kate Elton and Katie Espiner at Harper Fiction, in a major deal, for publication through 2017, by Toby Eady at Toby Eady Associates (world English).\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[dx['Editor'].apply(len)>0]['All'][88]#14067 #14042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d1b396e-c47f-4a17-95dc-30a57135eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "td= nlp(\"Author of MY SISTER'S SECRET Tracy Buchanan's THE WEIGHT OF SILENCE, in which a physiotherapist comes home from work to find her husband unconscious on the floor with a stab wound and their three children standing around him; it's clear he has been stabbed by one of them, but none of them is willing to say who did it or why, and THE WOMAN IN THE WOODS, to Sammia Hamer at Lake Union Publishing, in a very nice deal, by Caroline Hardman at Hardman & Swainson (world English).\\ncaroline@hardmanswainson.com\\nRights: Therese Coen at Hardman & Swainson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b85cad49-2682-413f-8356-8e5caa5a56c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracy Buchanan's PERSON\n",
      "three CARDINAL\n",
      "one CARDINAL\n",
      "Sammia Hamer GPE\n",
      "Lake Union Publishing ORG\n",
      "Caroline Hardman PERSON\n",
      "Hardman & Swainson ORG\n",
      "English LANGUAGE\n",
      "Hardman & Swainson ORG\n"
     ]
    }
   ],
   "source": [
    "for d in td.ents:\n",
    "    print(d, d.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bb30b4b-27d4-45b5-be3e-8d748751ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/rathod.rak/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/rathod.rak/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/rathod.rak/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import ne_chunk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21faaf76-ca73-4284-8c59-549896a5136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(\"Matthew Wilson's THE BLACKBIRD SINGULARITY, a first-person literary novel about the struggle to start a new life after losing a child, to Lauren Parsons at Legend Press, in a nice deal, by David Haviland at the Andrew Lownie Literary Agency (World English).\")\n",
    "words = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3226a94-2b28-4dc9-8aad-aa315dca1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = [nltk.pos_tag(sentence) for sentence in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db4858eb-757a-42e1-9269-6051122e8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = [ne_chunk(tagged_sentence) for tagged_sentence in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39686f45-caa1-4680-88fe-c2aa93e9ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthew PERSON\n",
      "Wilson PERSON\n",
      "THE ORGANIZATION\n",
      "BLACKBIRD ORGANIZATION\n",
      "Lauren Parsons PERSON\n",
      "Legend Press ORGANIZATION\n",
      "David Haviland PERSON\n",
      "Andrew Lownie Literary Agency PERSON\n"
     ]
    }
   ],
   "source": [
    "for named_entity in named_entities:\n",
    "    for subtree in named_entity.subtrees():\n",
    "        if subtree.label() in ['PERSON', 'ORGANIZATION', 'LOCATION']:\n",
    "            entity = ' '.join([word for word, tag in subtree.leaves()])\n",
    "            entity_type = subtree.label()\n",
    "            print(entity, entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289a38d-4ba2-4a7f-b002-6547d1954cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa51363-116e-432a-a366-304764265b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c625217-0da1-4707-a9e2-22281197450f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67ff55-a02f-48f9-a8a9-66c6d48a137a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb62bd3-d901-441a-a50c-3c6731d52bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22ad31-9447-42f7-903b-5dcf52c172bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "378b3fda-c9c4-48c3-aee0-8ea48efa2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"to ([\\w\\s]+) and ([\\w\\s]+) at\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c9521a-4814-4b5a-b4c1-06da42b30cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[['Editor', 'Editor2']] = dx[dx['Editor'].apply(len)>1]['All'].str.extract(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00210783-dcbd-4fc4-8b48-73e8bb62e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-660f68b67564>:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx.loc[dx['Editor'].apply(len) > 1, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.contains(pattern),\n"
     ]
    }
   ],
   "source": [
    "dx.loc[dx['Editor'].apply(len) > 1, 'Editor'] = np.where(dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.contains(pattern),\n",
    "                                                        dx.loc[dx['Editor'].apply(len) > 1, 'All'].str.extract(pattern).apply(lambda x: x.tolist(), axis=1),\n",
    "                                                        np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71e1402d-58d1-42a4-a9ac-2d96cede90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"to ([\\w\\s]+) at\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "985b188d-c84c-4e9f-b718-1f3da886cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-ce4045569917>:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx.loc[dx['Editor'].isna(), 'Editor'] = np.where(dx.loc[dx['Editor'].isna(), 'All'].str.contains(pattern),\n"
     ]
    }
   ],
   "source": [
    "dx.loc[dx['Editor'].isna(), 'Editor'] = np.where(dx.loc[dx['Editor'].isna(), 'All'].str.contains(pattern),\n",
    "                                                        dx.loc[dx['Editor'].isna(), 'All'].str.extract(pattern).apply(lambda x: x.tolist(), axis=1),\n",
    "                                                        np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc8cb2de-bf7c-4fc2-b3a2-05703cdf8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.loc[dx['Editor'].isna() , 'Editor']  = dx.loc[dx['Editor'].isna(), 'All'].apply(lambda text : get_editor_ent_nlp_to(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5a3edda-d6f3-4c8e-a929-7bf6f6e77d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rights to Tui Sutherland's NY Times Bestselling WINGS OF FIRE series, to Gallimard in France, in a significant deal, in a 6-publisher auction, by Noemie Rollet at Eliane Benisti Agency; to Loewe in Germany, by Friederike Biesel at the Thomas Schlueck Agency; to Fundamento in Brazil, by Joao Paulo Riff at the Riff Agency; to Aspendos in Turkey, by Bengu Ayfer at Akcali Copyright Agency, all on behalf of Cecilia de la Campa and Steven Malk at Writers House.\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[dx['Editor'].apply(len)>2]['All'][5756]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47a904dd-4164-4439-864f-81373b9f6653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Drew Hayes's UNDEATH AND TAXES, the sequel to THE UTTERLY UNINTERESTING AND UNADVENTUROUS TALES OF FRED, THE VAMPIRE ACCOUNTANT, joining Fred on a new series of mini-adventures where not only the living dread tax season, to Reuts, in a nice deal, for publication in Summer 2015 (World English).\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[dx['Editor'].isna()]['All'][12909]#[5089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78062497-9358-4bc4-a0ee-e8120b029d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dx['Editor'][572])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13f9bd3d-2885-4027-9a0b-cbe508aea2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lisa Greenwald's THE SUMMER OF PINK & GREEN, sequel to MY LIFE IN PINK & GREEN, in which the family's new eco-spa business spawns as many mishaps as it does makeovers, to Maggie Lehrman at Amulet, in a very nice deal, for publication in 2012, by Alyssa Eisner Henkin at Trident Media Group (World English).\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[dx['Editor'].isna()]['All'][662]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27e4567b-e35d-442e-a218-b19356d71ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c0d2c1c92b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Editor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Editor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4624\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4625\u001b[0m         \"\"\"\n\u001b[0;32m-> 4626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4628\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "dx[dx['Editor'].apply(len)>1]['Editor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1bd7c22f-dc73-4a49-b833-c5143bf1caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a118bf5-ccb8-4f28-b870-e0ab50e6649a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Kristen Ciccarelli's,\n",
       " Kristen Pettit at Harper Teen,\n",
       " three,\n",
       " Fall 2017,\n",
       " Heather Flaherty,\n",
       " The Bent Agency,\n",
       " NA,\n",
       " Gollancz,\n",
       " UK,\n",
       " Gemma Cooper,\n",
       " The Bent Agency,\n",
       " Heather Flaherty,\n",
       " Gallimard Jeunesse,\n",
       " France,\n",
       " Corinne Marotte,\n",
       " L'Autre Agence,\n",
       " Heyne,\n",
       " Germany,\n",
       " Bastian Schlueck,\n",
       " Thomas Schlueck Agency,\n",
       " Nocturna,\n",
       " Spain,\n",
       " Philip Sane,\n",
       " Lennart Sane Agency,\n",
       " Companhia das Letras,\n",
       " Brazil,\n",
       " Philip Sane,\n",
       " Lennart Sane Agency,\n",
       " Poland,\n",
       " Magda Cabajewska,\n",
       " the Macadamia Literary Agency,\n",
       " Dogan Egmont,\n",
       " Turkey,\n",
       " Asli Ermis,\n",
       " Asli Karasuil Telif Literary Agency,\n",
       " Blossom Books,\n",
       " Netherlands,\n",
       " Lester Hekking of Sebes & Bisseling,\n",
       " Dana Spector)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "135867c5-1947-4154-b95d-3849b00882bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.loc[dx['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'] = dx.loc[dx['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'].apply(lambda x: ', '.join(map(str, x)))\n",
    "dx.loc[dx['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'] = dx.loc[dx['Editor'].apply(lambda x: isinstance(x, list)), 'Editor'].apply(lambda x: x[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b784eff-93fd-4648-832e-687e9c8e1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93640d49-1f1f-40b9-8bc8-8a847fb2fd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f49a325-c989-40e6-b943-7db2069ddaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dx = pd.read_csv('Files/Editor_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f0b070c-d2a4-4643-9509-baf91a7a40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dx['All'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1f7c946-f351-4a56-bb76-9d2ef575eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46d5e274-68f9-4b5f-8842-ecfa58d4a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilary Mantel's\n"
     ]
    }
   ],
   "source": [
    "for d in doc.ents:\n",
    "    if \"'s\" in d.text:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e158b6-1a61-4411-a5b2-701c0f556afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766eeaa-f378-4292-9ad4-5d93c241292d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
